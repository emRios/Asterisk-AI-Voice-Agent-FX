active_pipeline: hybrid_deepinfra
asterisk:
  app_name: asterisk-ai-voice-agent
audio_transport: audiosocket
audiosocket:
  format: slin
  host: "10.132.112.148"
  port: 9092
barge_in:
  enabled: true
  energy_threshold: 30
  initial_protection_ms: 60
  min_ms: 80
  post_tts_end_protection_ms: 200
config_version: 4
contexts:
  default:
    greeting: Hello
    profile: telephony_ulaw_8k
    prompt: You are Asterisk, a Assistant. Be helpful and concise.
    provider: deepgram
  # Example context with background music (AAVA-89)
  # background_music references a MOH class from /etc/asterisk/musiconhold.conf
  # Place audio files in /var/lib/asterisk/moh/{class-name}/ (pre-reduced volume recommended)
  # demo_with_music:
  #   greeting: Welcome to our premium line!
  #   profile: telephony_ulaw_8k
  #   provider: deepgram
  #   background_music: default  # MOH class name
default_provider: deepgram
downstream_mode: stream
external_media:
  codec: ulaw
  direction: both
  format: slin16
  port_range: 18080:18099
  rtp_host: 127.0.0.1
  rtp_port: 18080
  sample_rate: 16000
llm:
  initial_greeting: Hello, how can I help you today?
  prompt: Voice assistant. Answer in 5-8 words. Be direct. Expand only if asked.
pipelines:
  # Nuevo pipeline híbrido:
  # STT: Deepgram (REST / streaming según options.stt)
  # LLM: DeepInfra (OpenAI-compatible) vía openai_llm
  # TTS: Deepgram TTS
  hybrid_deepinfra:
    stt: deepgram_stt
    llm: openai_llm
    tts: deepgram_tts
    options:
      stt:
        # DeepgramSTTAdapter lee estas claves y las mezcla con providers.deepgram
        api_key: ${DEEPGRAM_API_KEY}
        base_url: https://api.deepgram.com
        model: nova-2-general
        language: es
        encoding: linear16          # Audio hacia la API Deepgram (el adapter convierte desde PCM16 interno)
        sample_rate: 16000
        smart_format: true
        response_timeout_sec: 5.0
        streaming: false            # true si más adelante quieres WebSocket STT continuo
      llm:
        # OpenAILLMAdapter, usando DeepInfra como backend OpenAI-compatible
        api_key: ${DEEPINFRA_API_KEY}
        base_url: https://api.deepinfra.com/v1/openai
        model: gpt-4o-mini
        max_tokens: 256
        temperature: 0.7
        response_timeout_sec: 8.0
      tts:
        # Deepgram TTS vía REST (DeepgramTTSAdapter usará estos campos)
        api_key: ${DEEPGRAM_API_KEY}
        base_url: https://api.deepgram.com
        model: aura-2-selena-es
        encoding: mulaw
        sample_rate: 8000
        response_timeout_sec: 8.0

  # Pipeline original local_hybrid se mantiene como referencia (no activo)
  local_hybrid:
    llm: openai_llm
    options:
      llm:
        base_url: https://api.openai.com/v1
        max_tokens: 200
        model: gpt-4o-mini
        temperature: 0.7
      stt:
        chunk_ms: 160
        mode: stt
        stream_format: pcm16_16k
        streaming: true
      tts:
        mode: tts
        response_timeout_sec: 30.0
        format:
          encoding: mulaw
          sample_rate: 8000
    tools:
    - transfer
    - cancel_transfer
    - hangup_call
    - leave_voicemail
    - send_email_summary
    - request_transcript

profiles:
  default: telephony_responsive
  openai_realtime_24k:
    chunk_ms: 20
    idle_cutoff_ms: 0
    internal_rate_hz: 24000
    provider_pref:
      input_encoding: pcm16
      input_sample_rate_hz: 24000
      output_encoding: pcm16
      output_sample_rate_hz: 24000
    transport_out:
      encoding: slin
      sample_rate_hz: 8000
  telephony_responsive:
    chunk_ms: auto
    idle_cutoff_ms: 600
    internal_rate_hz: 8000
    provider_pref:
      input_encoding: mulaw
      input_sample_rate_hz: 8000
      output_encoding: mulaw
      output_sample_rate_hz: 8000
    transport_out:
      encoding: slin
      sample_rate_hz: 8000
  telephony_ulaw_8k:
    chunk_ms: auto
    idle_cutoff_ms: 800
    internal_rate_hz: 8000
    provider_pref:
      input_encoding: mulaw
      input_sample_rate_hz: 8000
      output_encoding: mulaw
      output_sample_rate_hz: 8000
    transport_out:
      encoding: ulaw
      sample_rate_hz: 8000
  wideband_pcm_16k:
    chunk_ms: auto
    idle_cutoff_ms: 1200
    internal_rate_hz: 16000
    provider_pref:
      input_encoding: linear16
      input_sample_rate_hz: 16000
      output_encoding: linear16
      output_sample_rate_hz: 16000
    transport_out:
      encoding: slin16
      sample_rate_hz: 16000
providers:
  deepgram:
    capabilities:
    - stt
    - llm
    - tts
    continuous_input: true
    enabled: true
    greeting: Hello, how can I help you today?
    input_encoding: mulaw
    input_gain_max_db: 0
    input_gain_target_rms: 0
    input_sample_rate_hz: 8000
    instructions: Voice assistant. Answer in 5-8 words. Be direct. Expand only if asked.
    model: "nova"
    language: es
    output_encoding: mulaw
    output_sample_rate_hz: 8000
    tts_model: "aura-2-selena-es"
    type: full
  google_live:
    api_key: ${GOOGLE_API_KEY}
    capabilities:
    - stt
    - llm
    - tts
    continuous_input: true
    enable_input_transcription: true
    enable_output_transcription: true
    enabled: true
    greeting: ${GOOGLE_LIVE_GREETING:-Hi! I'm powered by Google Gemini Live API. Try interrupting me!}
    input_encoding: ulaw
    input_gain_max_db: 0
    input_gain_target_rms: 0
    input_sample_rate_hz: 8000
    llm_max_output_tokens: 8192
    llm_model: gemini-2.0-flash-live
    llm_temperature: 0.8
    llm_top_k: 40
    llm_top_p: 0.95
    output_encoding: linear16
    output_sample_rate_hz: 24000
    provider_input_encoding: linear16
    provider_input_sample_rate_hz: 16000
    response_modalities: audio
    target_encoding: ulaw
    target_sample_rate_hz: 8000
    tts_voice_name: Aoede
    type: full
  local:
    base_url: ${LOCAL_WS_URL:-ws://127.0.0.1:8765}
    capabilities:
    - stt
    - llm
    - tts
    chunk_ms: ${LOCAL_WS_CHUNK_MS:=320}
    connect_timeout_sec: ${LOCAL_WS_CONNECT_TIMEOUT:=2.0}
    continuous_input: true
    enabled: false
    # Farewell mode: how to play goodbye when call ends
    # "tts" - Use local TTS (best for fast hardware with <5s LLM response time)
    # "asterisk" - Use Asterisk's built-in goodbye sound (reliable for slow hardware)
    farewell_mode: ${LOCAL_FAREWELL_MODE:=asterisk}
    # Farewell TTS timeout (only used when farewell_mode="tts")
    # Set based on LLM warmup time shown in logs (e.g., if warmup is 20s, set to 25-30s)
    farewell_timeout_sec: ${LOCAL_FAREWELL_TIMEOUT:=30.0}
    greeting: Hello! I'm your local AI assistant running entirely on-premises.
    instructions: You are a helpful voice assistant running locally. Be concise and friendly.
    llm_model: models/llm/phi-3-mini-4k-instruct.Q4_K_M.gguf
    max_tokens: 64
    response_timeout_sec: ${LOCAL_WS_RESPONSE_TIMEOUT:=10.0}
    stt_model: models/stt/vosk-model-en-us-0.22
    temperature: 0.4
    tts_voice: models/tts/en_US-lessac-medium.onnx
    type: full
  local_llm:
    capabilities:
    - llm
    enabled: false
    llm_model: models/llm/phi-3-mini-4k-instruct.Q4_K_M.gguf
    max_tokens: 32
    temperature: 0.4
    type: local
    ws_url: ${LOCAL_WS_URL:-ws://127.0.0.1:8765}
  local_stt:
    capabilities:
    - stt
    chunk_ms: ${LOCAL_WS_CHUNK_MS:=320}
    connect_timeout_sec: ${LOCAL_WS_CONNECT_TIMEOUT:=2.0}
    enabled: false
    response_timeout_sec: ${LOCAL_WS_RESPONSE_TIMEOUT:=10.0}
    stt_backend: vosk
    stt_model: models/stt/vosk-model-en-us-0.22
    type: local
    ws_url: ${LOCAL_WS_URL:-ws://127.0.0.1:8765}
  local_tts:
    capabilities:
    - tts
    enabled: false
    response_timeout_sec: ${LOCAL_WS_RESPONSE_TIMEOUT:=10.0}
    tts_voice: models/tts/en_US-lessac-medium.onnx
    type: local
    ws_url: ${LOCAL_WS_URL:-ws://127.0.0.1:8765}
  openai_llm:
    capabilities:
      - llm
    enabled: true
    # Apuntamos a DeepInfra como backend OpenAI-compatible
    chat_base_url: ${DEEPINFRA_BASE_URL}
    chat_model: gpt-4o-mini
    enabled: false
    response_timeout_sec: 5
    temperature: 0.7
    type: openai
  openai_realtime:
    base_url: wss://api.openai.com/v1/realtime
    capabilities:
    - stt
    - llm
    - tts
    continuous_input: true
    egress_pacer_enabled: true
    egress_pacer_warmup_ms: 320
    enabled: false
    greeting: Hello, how can I help you today?
    input_encoding: ulaw
    input_gain_max_db: 0
    input_gain_target_rms: 0
    input_sample_rate_hz: 8000
    instructions: "You are a voice assistant. Always speak your responses out loud."
    max_response_output_tokens: 4096
    model: gpt-4o-realtime-preview-2024-12-17
    organization: ''
    output_encoding: linear16
    output_sample_rate_hz: 24000
    provider_input_encoding: linear16
    provider_input_sample_rate_hz: 24000
    # CRITICAL: audio must be first for modalities priority
    response_modalities:
    - audio
    - text
    target_encoding: mulaw
    target_sample_rate_hz: 8000
    # Lower temperature for more consistent audio output
    temperature: 0.6
    turn_detection:
      create_response: true
      prefix_padding_ms: 300
      silence_duration_ms: 1000  # Standard - wait 1s before response
      threshold: 0.5  # Standard threshold - 0.8 was blocking user speech
      type: server_vad
    type: openai_realtime
    voice: alloy
  elevenlabs_agent:
    # ElevenLabs Conversational AI - Full Agent Provider
    # Requires: ELEVENLABS_API_KEY and ELEVENLABS_AGENT_ID in .env
    # Create an agent at https://elevenlabs.io/app/agents and copy the agent_id
    type: full
    enabled: false
    capabilities:
    - stt
    - llm
    - tts
    # Audio input from telephony
    input_encoding: ulaw
    input_sample_rate_hz: 8000
    # ElevenLabs native format (internal resampling)
    provider_input_encoding: pcm16
    provider_input_sample_rate_hz: 16000
    # Output from ElevenLabs
    output_encoding: pcm16
    output_sample_rate_hz: 16000
    # Target for telephony
    target_encoding: ulaw
    target_sample_rate_hz: 8000
    # Voice settings
    voice_id: "uDsPstFWFBUXjIBimV7s"  # User specified voice
    model_id: eleven_flash_v2_5       # Fast model for conversations
    voice_settings:
      stability: 0.5
      similarity_boost: 0.75
      style: 0.0
      use_speaker_boost: true
    # Agent behavior
    greeting: Hello! I'm your ElevenLabs voice assistant. How can I help you today?
    instructions: You are a helpful voice assistant. Be concise and friendly.
    continuous_input: true
    input_gain_target_rms: 0
    input_gain_max_db: 0
  openai_stt:
    chunk_size_ms: 20
    enabled: false
    input_encoding: linear16
    input_sample_rate_hz: 16000
    stt_model: whisper-1
    type: openai
  openai_tts:
    enabled: false
    target_encoding: mulaw
    target_sample_rate_hz: 8000
    tts_base_url: https://api.openai.com/v1/audio/speech
    tts_model: gpt-4o-mini-tts
    type: openai
    voice: alloy
streaming:
  chunk_size_ms: 20
  connection_timeout_ms: 120000
  continuous_stream: true
  diag_enable_taps: true
  diag_out_dir: /tmp/ai-engine-taps
  diag_post_secs: 1
  diag_pre_secs: 1
  empty_backoff_ticks_max: 5
  fallback_timeout_ms: 8000
  greeting_min_start_ms: 40
  jitter_buffer_ms: 100
  keepalive_interval_ms: 5000
  low_watermark_ms: 200
  min_start_ms: 300
  normalizer:
    enabled: true
    max_gain_db: 18
    target_rms: 1400
  provider_grace_ms: 200
  sample_rate: 8000
tools:
  ai_identity:
    name: AI Agent
    number: '6789'
  cancel_transfer:
    allow_after_answer: false
    allow_during_ring: true
    enabled: true
  default_action_timeout: 30
  enabled: true
  extensions:
    internal:
      '6000':
        action_type: transfer
        aliases:
        - agent
        - representative
        - human
        - real person
        - live person
        - someone
        - support
        - sales
        - operator
        - help desk
        description: Live customer service representative
        dial_string: SIP/6000
        mode: warm
        name: Live Agent
        pass_caller_info: true
        timeout: 30
        transfer: true
  hangup_call:
    enabled: true
    farewell_message: Thank you for calling. Goodbye!
    require_confirmation: false
  leave_voicemail:
    enabled: true
    extension: '2765'
  request_transcript:
    admin_email: haider@jugaar.llc
    api_key: ${RESEND_API_KEY}
    common_domains:
    - gmail.com
    - yahoo.com
    - outlook.com
    - hotmail.com
    - icloud.com
    confirm_email: true
    enabled: true
    from_email: ava@jugaar.llc
    from_name: AI Voice Agent
    max_attempts: 2
    provider: resend
    validate_domain: true
  send_email_summary:
    admin_email: haider@jugaar.llc
    api_key: ${RESEND_API_KEY}
    enabled: true
    from_email: ava@jugaar.llc
    from_name: AI Voice Agent
    include_metadata: true
    include_transcript: true
    provider: resend
  transfer:
    destinations:
      sales_agent:
        description: Sales agent
        target: '2765'
        type: extension
      sales_queue:
        description: Sales team queue
        target: '300'
        type: queue
      sales_team:
        description: Sales team ring group
        target: '600'
        type: ringgroup
      support_agent:
        description: Support agent
        target: '6000'
        type: extension
      support_queue:
        description: Technical support queue
        target: '301'
        type: queue
      support_team:
        description: Support team ring group
        target: '601'
        type: ringgroup
    enabled: true
    # Call event notification tool - business events to Redis Streams
  CallEventNotification:
    # Backend de cola a utilizar por la tool
    queue_backend: redis

    # Configuración específica de Redis para esta tool
    redis:
      # URL de conexión a Redis; se puede sobreescribir con la variable de entorno REDIS_URL
      url: ${REDIS_URL:-redis://127.0.0.1:6379/0}
      # Nombre del stream donde se publicarán los eventos de llamada
      stream_name: call_events
      # Longitud máxima del stream antes de recortar (estrategia aproximada)
      max_stream_length: 10000

    # Tipos de eventos que esta tool está autorizada a publicar
    enabled_event_types:
      - PURCHASE_INTENT_HIGH
      - TRANSFER_REQUESTED
      - HARD_REJECTION
      - SOFT_REJECTION
      - ESCALATION_REQUIRED
      - POSITIVE_FEEDBACK
      - NEGATIVE_FEEDBACK
    enabled: true
vad:
  enhanced_enabled: true
  fallback_buffer_size: 128000
  fallback_enabled: true
  fallback_interval_ms: 4000
  max_utterance_duration_ms: 10000
  min_utterance_duration_ms: 600
  #use_provider_vad: false
  utterance_padding_ms: 200
  webrtc_aggressiveness: 1
  webrtc_end_silence_frames: 50
  webrtc_start_frames: 3
  silence_duration_ms: 800
